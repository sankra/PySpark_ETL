# PySpark_ETL
A scalable and efficient ETL pipeline using PySpark, AWS, and Apache Airflow to process large-scale data. Includes data extraction, transformation, and loading into a data warehouse with performance optimizations.
