PySpark ETL: Read from AWS S3 â†’ Transform â†’ Load into AWS RDS ðŸš€
This PySpark script demonstrates how to:
âœ… Extract data from AWS S3 (CSV file).
âœ… Transform the data (filter, rename, and add a new column).
âœ… Load the transformed data into an AWS RDS (MySQL/PostgreSQL) database.



ðŸ”¹ Explanation of Steps
âœ… Extract: Read CSV from AWS S3 using spark.read.format("csv").
âœ… Transform: Performing basic data transformations using python or PySpark             


Rename a column (withColumnRenamed).

Add a new column (withColumn).

Filter records (filter).
âœ… Load: Use JDBC connection to insert data into AWS RDS.
